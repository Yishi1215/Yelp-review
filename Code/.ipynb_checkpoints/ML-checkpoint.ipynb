{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import Imputer, FunctionTransformer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yishi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/yishi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars        date                                               text  \\\n",
       "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
       "1      5  2016-05-28  Small unassuming place that changes their menu...   \n",
       "2      5  2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
       "3      4  2016-05-28  Love coming here. Yes the place always needs t...   \n",
       "4      4  2016-05-28  Had their chocolate almond croissant and it wa...   \n",
       "\n",
       "   useful  funny  cool  \n",
       "0       0      0     0  \n",
       "1       0      0     0  \n",
       "2       0      0     0  \n",
       "3       0      0     0  \n",
       "4       0      0     0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review = pd.read_csv('../Data/yelp_review.csv',index_col=False)\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to present the age of the comments\n",
    "df_review['date'] = pd.to_datetime(df_review['date'])\n",
    "today = datetime.strptime('7/23/2018', \"%m/%d/%Y\")\n",
    "df_review['days'] = (today - df_review['date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to show the average useful count for the user_id\n",
    "df_user = df_review[['user_id','useful']]\n",
    "df_user = df_user.groupby(['user_id']).mean().reset_index()\n",
    "df_user.columns = ['user_id', 'avg_useful_count']\n",
    "df = pd.merge(df_review, df_user, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>days</th>\n",
       "      <th>avg_useful_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars       date                                               text  \\\n",
       "0      5 2016-05-28  Super simple place but amazing nonetheless. It...   \n",
       "1      5 2016-05-28  Small unassuming place that changes their menu...   \n",
       "2      5 2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
       "3      4 2016-05-28  Love coming here. Yes the place always needs t...   \n",
       "4      4 2016-05-28  Had their chocolate almond croissant and it wa...   \n",
       "\n",
       "   useful  funny  cool  days  avg_useful_count  \n",
       "0       0      0     0   786               0.0  \n",
       "1       0      0     0   786               0.0  \n",
       "2       0      0     0   786               0.0  \n",
       "3       0      0     0   786               0.0  \n",
       "4       0      0     0   786               0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_review.sort_values('useful', ascending = False).iloc[0:19999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using langdetect to detect language of the comments and only includes English comments\n",
    "\n",
    "language=[] # list which will contain the language of the comments\n",
    "for i in df.text.values:\n",
    "    try:\n",
    "        lan =detect(i)\n",
    "        language.append(lan)\n",
    "        \n",
    "    except:\n",
    "        language.append('unknown')\n",
    "\n",
    "df['language']=language\n",
    "df = df.loc[df['language']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctions\n",
    "def remove_punctuation(text):\n",
    "    '''a function for removing punctuation'''\n",
    "    import string\n",
    "    # replacing the punctuations with no space, \n",
    "    # which in effect deletes the punctuation marks \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # return the text stripped of punctuation marks\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['text'] = df['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>days</th>\n",
       "      <th>language</th>\n",
       "      <th>textCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5252384</th>\n",
       "      <td>A8mLBytNM2zmjHgSpsuZDA</td>\n",
       "      <td>qiTy11I-yp6foxIghRfGOA</td>\n",
       "      <td>DN0b4Un8--Uf6SEWLeh0UA</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-08-01</td>\n",
       "      <td>In retrospect I should have known better than ...</td>\n",
       "      <td>3364</td>\n",
       "      <td>1481</td>\n",
       "      <td>1105</td>\n",
       "      <td>2913</td>\n",
       "      <td>en</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741187</th>\n",
       "      <td>69suGHxR3PVxicAgmUlhzA</td>\n",
       "      <td>XmIsBXpdBevTYCe8gKQruQ</td>\n",
       "      <td>DN0b4Un8--Uf6SEWLeh0UA</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>We were very disappointed with this restaurant...</td>\n",
       "      <td>2133</td>\n",
       "      <td>870</td>\n",
       "      <td>245</td>\n",
       "      <td>2073</td>\n",
       "      <td>en</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826731</th>\n",
       "      <td>NVeCBLhxOBQbSGLIeH5uAw</td>\n",
       "      <td>-nlHAaKCQF5I0GbbwrJo4A</td>\n",
       "      <td>DN0b4Un8--Uf6SEWLeh0UA</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>Was in Arizona to do comedy  This place isnt f...</td>\n",
       "      <td>1698</td>\n",
       "      <td>628</td>\n",
       "      <td>264</td>\n",
       "      <td>1902</td>\n",
       "      <td>en</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674533</th>\n",
       "      <td>OjV1om_QEFEs5iHYMKeONA</td>\n",
       "      <td>T8LqkYbwMPZmvXSsUfN8sQ</td>\n",
       "      <td>DN0b4Un8--Uf6SEWLeh0UA</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-12-13</td>\n",
       "      <td>I went to ABC during the filming of Kitchen Ni...</td>\n",
       "      <td>1608</td>\n",
       "      <td>351</td>\n",
       "      <td>319</td>\n",
       "      <td>2048</td>\n",
       "      <td>en</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875851</th>\n",
       "      <td>-N9mXK4k2Fwy2TUgVOhQDw</td>\n",
       "      <td>4vpZToBSrgo1yb48u9OGUg</td>\n",
       "      <td>DN0b4Un8--Uf6SEWLeh0UA</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>After seeing the Kitchen Nightmares episode an...</td>\n",
       "      <td>1525</td>\n",
       "      <td>522</td>\n",
       "      <td>198</td>\n",
       "      <td>1880</td>\n",
       "      <td>en</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      review_id                 user_id  \\\n",
       "5252384  A8mLBytNM2zmjHgSpsuZDA  qiTy11I-yp6foxIghRfGOA   \n",
       "2741187  69suGHxR3PVxicAgmUlhzA  XmIsBXpdBevTYCe8gKQruQ   \n",
       "826731   NVeCBLhxOBQbSGLIeH5uAw  -nlHAaKCQF5I0GbbwrJo4A   \n",
       "1674533  OjV1om_QEFEs5iHYMKeONA  T8LqkYbwMPZmvXSsUfN8sQ   \n",
       "2875851  -N9mXK4k2Fwy2TUgVOhQDw  4vpZToBSrgo1yb48u9OGUg   \n",
       "\n",
       "                    business_id  stars       date  \\\n",
       "5252384  DN0b4Un8--Uf6SEWLeh0UA      1 2010-08-01   \n",
       "2741187  DN0b4Un8--Uf6SEWLeh0UA      1 2012-11-18   \n",
       "826731   DN0b4Un8--Uf6SEWLeh0UA      1 2013-05-08   \n",
       "1674533  DN0b4Un8--Uf6SEWLeh0UA      2 2012-12-13   \n",
       "2875851  DN0b4Un8--Uf6SEWLeh0UA      1 2013-05-30   \n",
       "\n",
       "                                                      text  useful  funny  \\\n",
       "5252384  In retrospect I should have known better than ...    3364   1481   \n",
       "2741187  We were very disappointed with this restaurant...    2133    870   \n",
       "826731   Was in Arizona to do comedy  This place isnt f...    1698    628   \n",
       "1674533  I went to ABC during the filming of Kitchen Ni...    1608    351   \n",
       "2875851  After seeing the Kitchen Nightmares episode an...    1525    522   \n",
       "\n",
       "         cool  days language  textCount  \n",
       "5252384  1105  2913       en        743  \n",
       "2741187   245  2073       en        297  \n",
       "826731    264  1902       en        101  \n",
       "1674533   319  2048       en        623  \n",
       "2875851   198  1880       en        417  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['textCount'] = df['text'].str.split().str.len()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def stopwords(text):\n",
    "    '''a function for removing the stopword'''\n",
    "    # removing the stop words and lowercasing the selected words\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    # joining the list of words with space separator\n",
    "    return \" \".join(text)\n",
    "\n",
    "df['text'] = df['text'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming operations\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stemming(text):    \n",
    "    '''a function which stems each word in the given text'''\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text) \n",
    "\n",
    "df['text'] = df['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(df['text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['useful'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Linear Regression\n",
      "R^2: -4.5491787421914545\n",
      "Root Mean Squared Error: 149.56444205446684\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print('Simple Linear Regression')\n",
    "print('R^2: {}'.format(reg.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "R^2: 0.049704352126698985\n",
      "Root Mean Squared Error: 61.89326145766831\n",
      "Alpha: 5.361336110051605\n"
     ]
    }
   ],
   "source": [
    "alpha = 10**np.linspace(10,-2,100)*0.5\n",
    "regr_cv = RidgeCV(alphas=alpha, normalize=True)\n",
    "ridge = regr_cv.fit(X_train, y_train)\n",
    "ridge_pred=ridge.predict(X_test)\n",
    "print('Ridge')\n",
    "print('R^2: {}'.format(ridge.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ridge_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))\n",
    "print('Alpha: {}'.format(ridge.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R^2: -4.416238982729581e-05\n",
      "Root Mean Squared Error: 63.492669607273115\n",
      "Alpha: 0.18824679033962358\n"
     ]
    }
   ],
   "source": [
    "regr_cv = LassoCV(alphas=alpha, normalize=True)\n",
    "lasso = regr_cv.fit(X_train, y_train)\n",
    "lasso_pred=lasso.predict(X_test)\n",
    "print('Lasso')\n",
    "print('R^2: {}'.format(lasso.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, lasso_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))\n",
    "print('Alpha: {}'.format(lasso.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_matrix = tfid_vectorizer.transform(df['text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfid_matrix, df['useful'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Linear Regression\n",
      "R^2: -0.7170509477542366\n",
      "Root Mean Squared Error: 83.19660205271353\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print('Simple Linear Regression')\n",
    "print('R^2: {}'.format(reg.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "R^2: 0.048589753537438996\n",
      "Root Mean Squared Error: 61.929548020439675\n",
      "Alpha: 3.0679536367065814\n"
     ]
    }
   ],
   "source": [
    "alpha = 10**np.linspace(10,-2,100)*0.5\n",
    "regr_cv = RidgeCV(alphas=alpha, normalize=True)\n",
    "ridge = regr_cv.fit(X_train, y_train)\n",
    "ridge_pred=ridge.predict(X_test)\n",
    "print('Ridge')\n",
    "print('R^2: {}'.format(ridge.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ridge_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))\n",
    "print('Alpha: {}'.format(ridge.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R^2: (<6573x62328 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 680917 stored elements in Compressed Sparse Row format>, 3234294     24\n",
      "2603534     27\n",
      "4198470     24\n",
      "3579760     25\n",
      "2059490     47\n",
      "4606456     22\n",
      "614812      23\n",
      "4974963     46\n",
      "2297199     21\n",
      "3532666     24\n",
      "3298799     30\n",
      "4661204     31\n",
      "4120085     23\n",
      "3410236     33\n",
      "754329      25\n",
      "640991      26\n",
      "4918434     34\n",
      "2170375     24\n",
      "4831807     38\n",
      "2187865     21\n",
      "1814896     25\n",
      "2735084     24\n",
      "2315042     27\n",
      "2035848     32\n",
      "3008567     23\n",
      "2927217     34\n",
      "2937391     33\n",
      "4831245    110\n",
      "2346551     22\n",
      "3501581     34\n",
      "          ... \n",
      "2617728     22\n",
      "3769800     21\n",
      "1031185    305\n",
      "3501603     21\n",
      "2519456     27\n",
      "721181      40\n",
      "5231099     33\n",
      "2035832     50\n",
      "3998168     28\n",
      "498362      25\n",
      "707930      43\n",
      "2256592     32\n",
      "1814906     24\n",
      "3416420     49\n",
      "4030848     27\n",
      "108543      21\n",
      "4084844     21\n",
      "2982976     23\n",
      "2260215     36\n",
      "2633831     24\n",
      "4717957     23\n",
      "2527348     22\n",
      "1310462     20\n",
      "5071528     26\n",
      "4564252     22\n",
      "3297627     33\n",
      "84356       23\n",
      "3791233     27\n",
      "516845      30\n",
      "2300912     26\n",
      "Name: useful, Length: 6573, dtype: int64)\n",
      "Root Mean Squared Error: 66.4486090345694\n",
      "Alpha: 0.0466301673441609\n"
     ]
    }
   ],
   "source": [
    "regr_cv = LassoCV(alphas=alpha, normalize=True)\n",
    "lasso = regr_cv.fit(X_train, y_train)\n",
    "lasso_pred=lasso.predict(X_test)\n",
    "print('Lasso')\n",
    "print('R^2: {}'.format((X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, lasso_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))\n",
    "print('Alpha: {}'.format(lasso.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer & LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -7.940426891451244\n",
      "Root Mean Squared Error: 139.086180143941\n"
     ]
    }
   ],
   "source": [
    "sample_df = df[['text', 'days', 'textCount', 'stars', 'useful']]\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['days', 'textCount', 'stars']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['text', 'days', 'textCount', 'stars']], \n",
    "                                                    sample_df['useful'] , \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', LinearRegression())\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer & LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -2.2642620945504466\n",
      "Root Mean Squared Error: 84.04219035562602\n"
     ]
    }
   ],
   "source": [
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', TfidfVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', LinearRegression())\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer & RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -0.028146021060292625\n",
      "Root Mean Squared Error: 47.16634803972447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', TfidfVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', RidgeCV(alphas=alpha, normalize=True))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer & RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -0.06100294634010961\n",
      "Root Mean Squared Error: 47.91407923362112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', RidgeCV(alphas=alpha, normalize=True))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer & LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -2.7994973721412464e-06\n",
      "Root Mean Squared Error: 46.516331798761406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', TfidfVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', LassoCV(alphas=alpha, normalize=True))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer & LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -2.7994973721412464e-06\n",
      "Root Mean Squared Error: 46.516331798761406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', LassoCV(alphas=alpha, normalize=True))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer & RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -0.06651122241665575\n",
      "Root Mean Squared Error: 48.038292987371946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', TfidfVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', RandomForestRegressor(n_estimators = 150, random_state = 42))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer & RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -0.037105899029178824\n",
      "Root Mean Squared Error: 47.37142008040726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', RandomForestRegressor(n_estimators = 150, random_state = 42))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
