{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import Imputer, FunctionTransformer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>friends</th>\n",
       "      <th>user_total_useful</th>\n",
       "      <th>user_average_stars</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>days</th>\n",
       "      <th>user_avg_useful</th>\n",
       "      <th>text_count</th>\n",
       "      <th>pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>super simple place amazing nonetheless around ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.251389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>small unassuming place changes menu every ofte...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.5</td>\n",
       "      <td>50</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>lesters located beautiful neighborhood since 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.295833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>love coming yes place always needs floor swept...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.5</td>\n",
       "      <td>61</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.192857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>chocolate almond croissant amazing light butte...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.5</td>\n",
       "      <td>397</td>\n",
       "      <td>786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars                                               text  useful  \\\n",
       "0      5  super simple place amazing nonetheless around ...       0   \n",
       "1      5  small unassuming place changes menu every ofte...       0   \n",
       "2      5  lesters located beautiful neighborhood since 1...       0   \n",
       "3      4  love coming yes place always needs floor swept...       0   \n",
       "4      4  chocolate almond croissant amazing light butte...       0   \n",
       "\n",
       "   user_review_count  friends  user_total_useful  user_average_stars  \\\n",
       "0                  6        1                  0                4.67   \n",
       "1                  6        1                  0                4.67   \n",
       "2                  6        1                  0                4.67   \n",
       "3                  6        1                  0                4.67   \n",
       "4                  6        1                  0                4.67   \n",
       "\n",
       "   business_stars  business_review_count  days  user_avg_useful  text_count  \\\n",
       "0             4.0                     84   786              0.0          35   \n",
       "1             4.5                     50   786              0.0          91   \n",
       "2             4.0                     70   786              0.0          67   \n",
       "3             3.5                     61   786              0.0         101   \n",
       "4             4.5                    397   786              0.0          41   \n",
       "\n",
       "        pol  \n",
       "0  0.251389  \n",
       "1  0.291667  \n",
       "2  0.295833  \n",
       "3  0.192857  \n",
       "4  0.530000  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('../Cleaned_Data/cleaned_data_v1.csv',index_col=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer & Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(X_train, X_test, y_train, y_test):\n",
    "    alpha = 10**np.linspace(10,-2,100)*0.5\n",
    "    regr_cv = LassoCV(alphas=alpha, normalize=True)\n",
    "    lasso = regr_cv.fit(X_train, y_train)\n",
    "    lasso_pred=lasso.predict(X_test)\n",
    "    print('Lasso')\n",
    "    print('R^2: {}'.format(lasso.score(X_test, y_test)))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, lasso_pred))\n",
    "    print('Root Mean Squared Error: {}'.format(rmse))\n",
    "    print('Alpha: {}'.format(lasso.alpha_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use text data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R^2: -0.0008802498832749528\n",
      "Root Mean Squared Error: 3.1488532387218284\n",
      "Alpha: 5000000000.0\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df=9)\n",
    "X = count_vect.fit_transform(df['text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['useful'], test_size=0.33, random_state=42)\n",
    "lasso(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use numeric data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R^2: 0.32329653184381335\n",
      "Root Mean Squared Error: 2.6003276258999133\n",
      "Alpha: 0.005\n"
     ]
    }
   ],
   "source": [
    "X = df[['stars', 'user_review_count', 'friends', 'user_total_useful',\n",
    "       'user_average_stars', 'business_stars', 'business_review_count', 'days',\n",
    "       'user_avg_useful', 'text_count', 'pol']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['useful'], test_size=0.3, random_state=42)\n",
    "lasso(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine text and numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.18188275429296086\n",
      "Root Mean Squared Error: 2.8977597245634095\n"
     ]
    }
   ],
   "source": [
    "df_ml = df[['text', 'stars', 'user_review_count', 'friends', 'user_total_useful',\n",
    "       'user_average_stars', 'business_stars', 'business_review_count', 'days',\n",
    "       'user_avg_useful', 'text_count', 'pol', 'useful']]\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['stars', 'user_review_count', 'friends', \n",
    "                                                    'user_total_useful','user_average_stars', 'business_stars', \n",
    "                                                    'business_review_count', 'days','user_avg_useful', \n",
    "                                                    'text_count', 'pol']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(df_ml)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(df_ml)\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_ml[['text', 'stars', 'user_review_count', 'friends', \n",
    "                                                           'user_total_useful','user_average_stars', 'business_stars', \n",
    "                                                           'business_review_count', 'days','user_avg_useful', \n",
    "                                                           'text_count', 'pol']], \n",
    "                                                    df_ml['useful'] , \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(min_df=7))\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', LassoCV(alphas=alpha, normalize=True))\n",
    "    ])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf & Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest tfidf:\n",
      "['something wrong went' 'said would another' 'eight hundred something'\n",
      " 'said would bout' 'see got test' 'driving told bill'\n",
      " 'drive unexpected thing' 'drive side door' 'drive said better'\n",
      " 'sends customers issues' 'door frame missing' 'door called relative'\n",
      " 'side door frame' 'side needs replaced' 'slammedmy truck curb'\n",
      " 'something annoyed wanted' 'end passenger side' 'something another part'\n",
      " 'said want truck' 'enough sorry much']\n",
      "\n",
      "Features with highest tfidf: \n",
      "['smack dab middle' 'duck confit poutine' 'service food good'\n",
      " 'dont think ill' 'lack good places' 'since first opened'\n",
      " 'dont waste money' 'dont waste time' 'short rib bone' 'las vegas many'\n",
      " 'service really slow' 'service ok food' 'service little slow'\n",
      " 'service hit miss' 'service great food' 'service great drinks'\n",
      " 'las vegas strip' 'drink menu solid' 'server friendly attentive'\n",
      " 'red velvet cake']\n"
     ]
    }
   ],
   "source": [
    "tfid_vectorizer = TfidfVectorizer(min_df=2, ngram_range=(3,3))\n",
    "tfid_matrix = tfid_vectorizer.fit_transform(df['text'])\n",
    "max_val = tfid_matrix.max(axis=0).toarray().ravel()\n",
    "feature_names = np.array(tfid_vectorizer.get_feature_names())\n",
    "#sort weights from smallest to biggest and extract their indices \n",
    "sort_by_tfidf = max_val.argsort()\n",
    "\n",
    "print(\"Features with lowest tfidf:\\n{}\".format(\n",
    "      feature_names[sort_by_tfidf[:20]]))\n",
    "\n",
    "print(\"\\nFeatures with highest tfidf: \\n{}\".format(\n",
    "      feature_names[sort_by_tfidf[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R^2: -0.0011672577379504556\n",
      "Root Mean Squared Error: 3.1628761601119724\n",
      "Alpha: 5000000000.0\n"
     ]
    }
   ],
   "source": [
    "tfid_vectorizer = TfidfVectorizer(min_df=5,ngram_range=(2,2))\n",
    "tfid_matrix = tfid_vectorizer.fit_transform(df['text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfid_matrix, df['useful'], test_size=0.3, random_state=42)\n",
    "lasso(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.22995005101270924\n",
      "Root Mean Squared Error: 2.8113443666001734\n"
     ]
    }
   ],
   "source": [
    "df_ml = df[['text', 'stars', 'user_review_count', 'friends', 'user_total_useful',\n",
    "       'user_average_stars', 'business_stars', 'business_review_count', 'days',\n",
    "       'user_avg_useful', 'text_count', 'pol', 'useful']]\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['stars', 'user_review_count', 'friends', \n",
    "                                                    'user_total_useful','user_average_stars', 'business_stars', \n",
    "                                                    'business_review_count', 'days','user_avg_useful', \n",
    "                                                    'text_count', 'pol']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(df_ml)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(df_ml)\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_ml[['text', 'stars', 'user_review_count', 'friends', \n",
    "                                                           'user_total_useful','user_average_stars', 'business_stars', \n",
    "                                                           'business_review_count', 'days','user_avg_useful', \n",
    "                                                           'text_count', 'pol']], \n",
    "                                                    df_ml['useful'] , \n",
    "                                                    random_state=22)\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', TfidfVectorizer(min_df=3,ngram_range=(4,5)))\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', LassoCV(alphas=alpha, normalize=True))\n",
    "    ])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "y_pred = pl.predict(X_test)\n",
    "print('R^2: {}'.format(pl.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ml = df[['text', 'stars', 'user_review_count', 'friends', 'user_total_useful',\n",
    "#        'user_average_stars', 'business_stars', 'business_review_count', 'days',\n",
    "#        'user_avg_useful', 'text_count', 'pol', 'useful']]\n",
    "\n",
    "# # Obtain the text data: get_text_data\n",
    "# get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# # Obtain the numeric data: get_numeric_data\n",
    "# get_numeric_data = FunctionTransformer(lambda x: x[['stars', 'user_review_count', 'friends', \n",
    "#                                                     'user_total_useful','user_average_stars', 'business_stars', \n",
    "#                                                     'business_review_count', 'days','user_avg_useful', \n",
    "#                                                     'text_count', 'pol']], validate=False)\n",
    "\n",
    "# # Fit and transform the text data: just_text_data\n",
    "# just_text_data = get_text_data.fit_transform(df_ml)\n",
    "\n",
    "# # Fit and transform the numeric data: just_numeric_data\n",
    "# just_numeric_data = get_numeric_data.fit_transform(df_ml)\n",
    "\n",
    "# # Split using ALL data in sample_df\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_ml[['text', 'stars', 'user_review_count', 'friends', \n",
    "#                                                            'user_total_useful','user_average_stars', 'business_stars', \n",
    "#                                                            'business_review_count', 'days','user_avg_useful', \n",
    "#                                                            'text_count', 'pol']], \n",
    "#                                                     df_ml['useful'] , \n",
    "#                                                     random_state=22)\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('u1', FeatureUnion(\n",
    "#         transformer_list = [\n",
    "#             ('numeric_features', Pipeline([\n",
    "#                 ('selector', get_numeric_data),\n",
    "#                 ('imputer', Imputer())\n",
    "#             ])),\n",
    "#             ('text_features', Pipeline([\n",
    "#                 ('selector', get_text_data),\n",
    "#                 ('vectorizer', TfidfVectorizer())\n",
    "#             ]))\n",
    "#         ]\n",
    "#     )),\n",
    "#     ('clf', LassoCV(alphas=alpha, normalize=True))\n",
    "# ])\n",
    "\n",
    "# parameters = {\n",
    "#     'u1__text_features__vectorizer__min_df': (1, 9),\n",
    "#     'u1__text_features__vectorizer__ngram_range': [(2, 3), (3, 4),(4, 5), (5, 6), (6, 7)]\n",
    "# }\n",
    "\n",
    "# clf = GridSearchCV(pipe, parameters)\n",
    "# clf.fit(X_train, y_train)\n",
    "# clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
